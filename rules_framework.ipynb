{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Выгрузка данных и импорт библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.tree import plot_tree\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import _tree\n",
    "import random\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_excel('data/X_train_with_scores.xlsx', sheet_name='sheet1')\n",
    "X_test = pd.read_excel('data/X_test_with_scores.xlsx', sheet_name='sheet1')\n",
    "X_out = pd.read_excel('data/X_out_with_scores.xlsx', sheet_name='sheet1')\n",
    "\n",
    "y_train = pd.read_excel('data/y_train_with_scores.xlsx', sheet_name='sheet1')\n",
    "y_test = pd.read_excel('data/y_test_with_scores.xlsx', sheet_name='sheet1')\n",
    "y_out = pd.read_excel('data/y_out_with_scores.xlsx', sheet_name='sheet1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.drop(columns=['Unnamed: 0'], axis=1, inplace=True)\n",
    "X_test.drop(columns=['Unnamed: 0'], axis=1, inplace=True)\n",
    "X_out.drop(columns=['Unnamed: 0'], axis=1, inplace=True)\n",
    "\n",
    "y_train.drop(columns=['Unnamed: 0'], axis=1, inplace=True)\n",
    "y_test.drop(columns=['Unnamed: 0'], axis=1, inplace=True)\n",
    "y_out.drop(columns=['Unnamed: 0'], axis=1, inplace=True)\n",
    "\n",
    "y_train.columns = ['target']\n",
    "y_test.columns = ['target']\n",
    "y_out.columns = ['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_drop = list()\n",
    "for col in X_train.columns:\n",
    "    if 'scor' in col or 'target' in col:\n",
    "        to_drop.append(col)\n",
    "X_train.drop(columns=to_drop, axis=1, inplace=True)\n",
    "X_test.drop(columns=to_drop, axis=1, inplace=True)\n",
    "X_out.drop(columns=to_drop, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6m_overdue2total_cnt_pdl\n",
      "1y_overdue2total_cnt_pdl\n",
      "1y_cnt_pdl\n",
      "3m_1y_overdue_cnt_pdl\n"
     ]
    }
   ],
   "source": [
    "for col in X_train.columns:\n",
    "    if col[0] in '1234567890':\n",
    "        new_name = 'a' + col\n",
    "        X_train[new_name] = X_train[col].copy()\n",
    "        X_test[new_name] = X_test[col].copy()\n",
    "        X_out[new_name] = X_out[col].copy()\n",
    "\n",
    "        X_train.drop(columns=[col], axis=1, inplace=True)\n",
    "        X_test.drop(columns=[col], axis=1, inplace=True)\n",
    "        X_out.drop(columns=[col], axis=1, inplace=True)\n",
    "        print(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обход деревьев без объединения веток в одном дереве"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tree_to_code(tree, feature_names, df, BR):\n",
    "\n",
    "    \"\"\"Функция рекурсивно проходится по заданному дереву, и в случае обнаружения ветки\n",
    "    с пониженным BR, записывает её путь и показатели(BR, segment_share) в итоговый список\"\"\"\n",
    "\n",
    "    tree_ = tree.tree_\n",
    "    feature_name = [\n",
    "        feature_names[i] if i != _tree.TREE_UNDEFINED else \"undefined!\"\n",
    "        for i in tree_.feature]\n",
    "    \n",
    "    result = list()\n",
    "\n",
    "    def recurse(node, depth, s):\n",
    "\n",
    "        if tree_.feature[node] != _tree.TREE_UNDEFINED:\n",
    "            name = feature_name[node]\n",
    "            threshold = round(tree_.threshold[node], 3)\n",
    "\n",
    "            sample_count = tree_.n_node_samples[node]\n",
    "            class_count = tree_.value[node][0]\n",
    "            segment_share = round(sample_count / len(df), 3)\n",
    "            bad_rate = round(class_count[1] / (class_count[0] + class_count[1]), 3)\n",
    "\n",
    "            if bad_rate < BR:\n",
    "                result.append((s[1:], round(bad_rate, 3), round(segment_share, 3)))\n",
    "                #print (\"rule: {}, curr_BR = {}, curr_SS {}:)\".format(s[1:], bad_rate, segment_share))\n",
    "            s1 = \"({} <= {})\".format(name, threshold)\n",
    "            recurse(tree_.children_left[node], depth + 1, s + '&' + s1)\n",
    "            s2 = \"({} > {})\".format(name, threshold)\n",
    "            recurse(tree_.children_right[node], depth + 1, s + '&' + s2)\n",
    "        else:\n",
    "            sample_count = tree_.n_node_samples[node]\n",
    "            class_count = tree_.value[node][0]\n",
    "            segment_share = round(sample_count / len(df), 3)\n",
    "            bad_rate = round(class_count[1] / (class_count[0] + class_count[1]), 3)\n",
    "            if bad_rate < BR:\n",
    "                result.append((s[1:], round(bad_rate, 3), round(segment_share, 3)))\n",
    "                #print (\"rule: {}, curr_BR = {}, curr_SS = {}:)\".format(s[1:], bad_rate, segment_share))\n",
    "\n",
    "    recurse(0, 1, '')\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rules_search(X_train, y_train, vars, BR_dwn=30):\n",
    "\n",
    "    \"\"\"Строит множество деревьев решений на рандомно извлечённых признаках из vars,\n",
    "    затем проходится по построенным деревьям, и в случае обнарежения ветки с достаточно\n",
    "    пониженным BR (больше указанного BR_dwn - в процентах), записывает данную ветку в итог.\n",
    "    \n",
    "    Функция возвращает датафрэйм с указанным рулом, BR-ом после его применения и долей остатка выборки\"\"\"\n",
    "\n",
    "    from sklearn.utils import shuffle\n",
    "    result_rules = list()\n",
    "    columns = vars\n",
    "\n",
    "    BR_curr = y_train.mean().values[0]\n",
    "    BR_need = BR_curr * (1 - BR_dwn/100)\n",
    "\n",
    "    for k in range(20):\n",
    "        columns = shuffle(columns, random_state=k)\n",
    "        for i in range(0, len(columns), 7):\n",
    "            curr = columns[i:i+7]\n",
    "            clf_tree = DecisionTreeClassifier(\n",
    "                max_depth=3,\n",
    "                min_samples_leaf=100\n",
    "            )\n",
    "            clf_tree.fit(X_train[curr], y_train.target)\n",
    "            vals = tree_to_code(clf_tree, curr, X_train, BR_need)\n",
    "    \n",
    "            result_rules += vals\n",
    "            \n",
    "    return pd.DataFrame(data=result_rules, columns=['rule', 'BR', 'Segm_share']).sort_values('Segm_share', ascending=False)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обход деревьев с объединением веток в одном дереве"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tree_to_code_up_down(tree, feature_names, df, y, BR):\n",
    "\n",
    "    \"\"\"Функция рекурсивно проходится по заданному дереву, и в случае обнаружения ветки\n",
    "    с пониженным BR, записывает её путь и показатели(BR, segment_share) в список. Теперь в списке лежат все ветки одного дерева с пониженным BR,\n",
    "    далее, я с помощью itertools.combinations(здесь можно юзать, так как в одном дереве максимум ветки 3 с пониженным BR), перебираю\n",
    "    все возможные вариации объединения этих веток в единое правило. Так-же все объединения проверяю на BR, и вывожу значение с самым больших Segm_share\"\"\"\n",
    "\n",
    "    tree_ = tree.tree_\n",
    "    feature_name = [\n",
    "        feature_names[i] if i != _tree.TREE_UNDEFINED else \"undefined!\"\n",
    "        for i in tree_.feature]\n",
    "    \n",
    "    result = list()\n",
    "\n",
    "    def recurse(node, depth, s):\n",
    "\n",
    "        if tree_.feature[node] != _tree.TREE_UNDEFINED:\n",
    "            name = feature_name[node]\n",
    "            threshold = round(tree_.threshold[node], 3)\n",
    "\n",
    "            sample_count = tree_.n_node_samples[node]\n",
    "            class_count = tree_.value[node][0]\n",
    "            segment_share = round(sample_count / len(df), 3)\n",
    "            bad_rate = round(class_count[1] / (class_count[0] + class_count[1]), 3)\n",
    "\n",
    "            if bad_rate < BR:\n",
    "                result.append((s[1:], round(bad_rate, 3), round(segment_share, 3)))\n",
    "                #print (\"rule: {}, curr_BR = {}, curr_SS {}:)\".format(s[1:], bad_rate, segment_share))\n",
    "                return\n",
    "\n",
    "            s1 = \"({} <= {})\".format(name, threshold)\n",
    "            recurse(tree_.children_left[node], depth + 1, s + '&' + s1)\n",
    "            s2 = \"({} > {})\".format(name, threshold)\n",
    "            recurse(tree_.children_right[node], depth + 1, s + '&' + s2)\n",
    "        else:\n",
    "            sample_count = tree_.n_node_samples[node]\n",
    "            class_count = tree_.value[node][0]\n",
    "            segment_share = round(sample_count / len(df), 3)\n",
    "            bad_rate = round(class_count[1] / (class_count[0] + class_count[1]), 3)\n",
    "            if bad_rate < BR:\n",
    "                result.append((s[1:], round(bad_rate, 3), round(segment_share, 3)))\n",
    "                #print (\"rule: {}, curr_BR = {}, curr_SS = {}:)\".format(s[1:], bad_rate, segment_share))\n",
    "            return\n",
    "\n",
    "    recurse(0, 1, '')\n",
    "\n",
    "    if len(result) <= 1:\n",
    "        return result[0]\n",
    "        \n",
    "    # result = sorted(result, key=lambda x: x[2], reverse=True)#Сортирую список по убыванию по segm_share\n",
    "\n",
    "    def search_comb(df, y, result):\n",
    "\n",
    "        import itertools\n",
    "        df['target'] = y.target\n",
    "\n",
    "        fin = list()\n",
    "        all_comb = []\n",
    "        for i in range(1, len(result)+1):\n",
    "            cr = itertools.combinations(range(len(result)), i)\n",
    "            all_comb += cr\n",
    "\n",
    "        for comb in all_comb:\n",
    "            curr_filt = ''\n",
    "            for ind in comb:\n",
    "                curr_filt += '|' + '(' + result[ind][0] + ')'\n",
    "            curr_filt = curr_filt[1:]\n",
    "            curr_BR = df.query(curr_filt).target.mean() #значение BR\n",
    "            curr_prt = (df.query(curr_filt).shape[0] / df.shape[0]) #часть оставшейся выборки\n",
    "            if curr_BR < BR:\n",
    "                fin.append((curr_filt, round(curr_BR, 3), round(curr_prt, 3)))\n",
    "                \n",
    "        df.drop(columns=['target'], axis=1, inplace=True)\n",
    "\n",
    "        return fin \n",
    "        \n",
    "    fin = search_comb(df, y, result)\n",
    "    fin = sorted(fin, key=lambda x: x[2], reverse=True) #Сортирую список по убыванию по segm_share и вывожу в результат лучшую комбинацию веток\n",
    "    return fin[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rules_search_up_down(X_train, y_train, vars, BR_dwn=30):\n",
    "\n",
    "    \"\"\"Строит множество деревьев решений на рандомно извлечённых признаках из vars,\n",
    "    затем проходится по построенным деревьям, и в случае обнарежения ветки с достаточно\n",
    "    пониженным BR (больше указанного BR_dwn - в процентах), записывает данную ветку в итог.\n",
    "    Если в одном дереве присутстует несколько веток с пониженным BR, \n",
    "    то функция их объединяет (по условиям BR_dwn - т.е. получаются 'деревья') и записывает в итог.\n",
    "    \n",
    "    Функция возвращает датафрэйм с указанным рулом, BR-ом после его применения и долей остатка выборки\"\"\"\n",
    "    from sklearn.utils import shuffle\n",
    "    result_rules = list()\n",
    "    columns = vars\n",
    "\n",
    "    BR_curr = y_train.mean().values[0]\n",
    "    BR_need = BR_curr * (1 - BR_dwn/100)\n",
    "\n",
    "    for k in range(20):\n",
    "        columns = shuffle(columns, random_state=k)\n",
    "        for i in range(0, len(columns), 7):\n",
    "            curr = columns[i:i+7]\n",
    "            clf_tree = DecisionTreeClassifier(\n",
    "                max_depth=3,\n",
    "                min_samples_leaf=100\n",
    "            )\n",
    "            clf_tree.fit(X_train[curr], y_train.target)\n",
    "            vals = tree_to_code_up_down(clf_tree, curr, X_train, y_train, BR_need)\n",
    "    \n",
    "            result_rules.append(vals)\n",
    "            \n",
    "    return pd.DataFrame(data=result_rules, columns=['rule', 'BR', 'Segm_share']).sort_values('Segm_share', ascending=False)      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ручной подбор фильтров \n",
    "(использовать при необходимости ручного подбора фильтров, функции не используются в основом расчёте)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_res_BR(X, y):\n",
    "\n",
    "    \"\"\"Функция принимает: \n",
    "                X - датафрэйм с необходимыми для фильтрации признаками\n",
    "                y - соответствующий датафрэйм, со значением таргета(необходим для расчёта значений)\n",
    "\n",
    "        Данная функция подходит для прописывания фильтров и анализа их способностей.\n",
    "    Подбирая различные комбинации признаков (vars_woe), на них можно строить деревья-решений, \n",
    "    смотреть на ветки с пониженныйм BR, и если он понизился на необходимую долю,\n",
    "    записать данную ветку как отдельный фильтр.\n",
    "    В дальнейшем, самостоятельно собирать фильтры в один (т.к. для расчёта фильтров используется функция \"query\",\n",
    "    принимающая в качестве агрумента строку, то объединять следует через конкатенацию\n",
    "    строк фильтров с \"|\" - логические \"или\", обособляя фильтры скобками) и первично оценивать взаимодействие полученный фильтров\"\"\"\n",
    "\n",
    "    X['target'] = y.target\n",
    "\n",
    "    # Пример прописывания рулов(фильтров)\n",
    "\n",
    "    f0 = '(target >= 0)'\n",
    "    f1 = '(capsL6m > 0.353)&(iss_am2sum_dpd > -0.449)&(crd_sum_IL2total > -0.449)'\n",
    "    f2 = '(capsL6m > 0.245)&(crd_sum_IL2total > -0.251)'\n",
    "    f3 = '(capsL3m > -0.075)&(iss_am2sum_dpd > -0.449)&(crd_sum_IL2total > -0.251)'\n",
    "    \n",
    "    # Пример объединения в единый фильтр\n",
    "\n",
    "    full_filtr = '(' + f1 + ')' + '|' + '(' + f2 + ')' + '|' + '(' + f3 + ')'\n",
    "\n",
    "    BR_dwn = round((1 - X.query(full_filtr).target.mean()/X.target.mean())*100, 3)\n",
    "    prt = round((X.query(full_filtr).shape[0] / X.shape[0]) * 100, 3)\n",
    "    BR_curr = round(X.query(full_filtr).target.mean()*100, 3)\n",
    "    \n",
    "    #Функция ворзвращает BR_dwn - на сколько процентов понизился BR от начального, после применения указанных фильтров\n",
    "    #                    prt - процент оставшейся выборки с пониженный BR (то, что осталость после среза фильтром)\n",
    "    #                    BR_curr - текущий BR на получившейся выборке\n",
    "\n",
    "    return BR_dwn, prt, BR_curr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BR_data_samples(X_train, X_test, X_out, y_train, y_test, y_out):\n",
    "\n",
    "    \"\"\"Функция принимает:\n",
    "                X_train, X_test, X_out - датафрэймы с необходимыми для фильтрации признаками\n",
    "                y_train, y_test, y_out - соответствующие df, со значением таргета(необходим для расчёта значений)\n",
    "        \n",
    "       Функция объединяет аналитику по объединённому фильтру в calculate_res_BR, для выборок train, test, out\"\"\"\n",
    "\n",
    "    BR_dwn_train, prt_train, BR_curr_train = calculate_res_BR(X_train, y_train)\n",
    "    BR_dwn_test, prt_test, BR_curr_test = calculate_res_BR(X_test, y_test)\n",
    "    BR_dwn_out, prt_out, BR_curr_out = calculate_res_BR(X_out, y_out)\n",
    "\n",
    "    df = pd.DataFrame(index=['train', 'test', 'out'], \n",
    "                      columns = ['BR_dwn', 'prt', 'BR_curr'], \n",
    "                      data = [[BR_dwn_train, prt_train, BR_curr_train], \n",
    "                              [BR_dwn_test, prt_test, BR_curr_test], \n",
    "                              [BR_dwn_out, prt_out, BR_curr_out]])\n",
    "    \n",
    "    #Ворзвращает датафрэйм со значениями BR_dwn, prt, BR_curr для всех выборок\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Основные функции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def filter_df(nums):\n",
    "\n",
    "#     #СТАРАЯ ФУНКЦИЯ, ПРИНИМАЕТ ТОЛЬКО ИНДЕКСЫ, ФИЛЬТРЫ НЕОБХОДИМО ПРОПИСЫВАТЬ ВРУЧНУЮ!\n",
    "    \n",
    "#     \"\"\"Функция принимает:\n",
    "#                 nums - индексы фильтров (номер фильтра минус 1)\n",
    "                         \n",
    "#        Предназначена для объединения фильтров для текущего датарфэма\n",
    "#        по определённым индексам(используется в последующих расчётных функциях)\"\"\"\n",
    "    \n",
    "#     #Фильтры, применяемые в данной функции, копировать(просто строками) из отобранных фильтров в функции 'calculate_res_BR'\n",
    "\n",
    "#     # Пример прописывания веток с пониженный BR\n",
    "\n",
    "#     f1 = '(feat1 > 0.353)&(feat2 > -0.449)&(feat3 > -0.449)'\n",
    "#     f2 = '(feat4 > 0.353)&(feat5 > -0.449)&(feat6 > -0.449)'\n",
    "\n",
    "\n",
    "\n",
    "#     #Необходимо прописать полученные фильтры в виде списка\n",
    "#     # (лучше нумеровать фильтры - 1, 2, 3..., чтобы в дальнейшем не было путаницы с номерами)\n",
    "\n",
    "#     #Пример\n",
    "\n",
    "#     filters = [f1, f2]\n",
    "\n",
    "#     res_filt = '(' + filters[nums[0]] + ')'\n",
    "#     if len(nums) == 1:\n",
    "#         return res_filt\n",
    "#     for i in range(1, len(nums)):\n",
    "#         res_filt += '|' + '(' + filters[nums[i]] + ')'\n",
    "\n",
    "#     #Возвращает:\n",
    "#     #       res_filt - объединённые фильтры в виде строки\n",
    "#     return res_filt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_df(nums, filters_list):\n",
    "    \n",
    "    \"\"\"Функция принимает:\n",
    "                nums - индексы фильтров (номер фильтра минус 1)\n",
    "                filters_list - общий список фильтров, идущий на фильтрацию\n",
    "\n",
    "       Предназначена для объединения фильтров для датарфэма\n",
    "       по определённым индексам.\n",
    "       (используется в последующих расчётных функциях)\"\"\"\n",
    "    \n",
    "\n",
    "    filters = filters_list.copy()\n",
    "\n",
    "    res_filt = '(' + filters[nums[0]] + ')'\n",
    "    if len(nums) == 1:\n",
    "        return res_filt\n",
    "    for i in range(1, len(nums)):\n",
    "        res_filt += '|' + '(' + filters[nums[i]] + ')'\n",
    "\n",
    "    #Возвращает:\n",
    "    #       res_filt - объединённые фильтры в виде строки\n",
    "    return res_filt\n",
    "\n",
    "\n",
    "def calculate_values(df, filters):\n",
    "\n",
    "    \"\"\"Фукнция принимает: \n",
    "                df - фильтруемый датафрэйм (уже с колонкой таргета)\n",
    "                filters - строка с комбинацией фильтров\"\"\"\n",
    "\n",
    "    BR_dwn = round((1 - df.query(filters, engine='python').target.mean()/df.target.mean())*100, 3) #снижение BR в %\n",
    "    prt = round((df.query(filters, engine='python').shape[0] / df.shape[0])*100, 3) #часть оставшейся выборки\n",
    "    BR_curr = round(df.query(filters, engine='python').target.mean()*100, 3) #значение BR\n",
    "    #Возваращает значения BR_dwn, prt, BR_curr для отфильтрованного датафрэйма \n",
    "    return BR_dwn, prt, BR_curr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_step_by_step_learn(X_train, y_train, filters_list, trsh_hld=30):\n",
    "\n",
    "    \"\"\"Функция принимает:\n",
    "            X_train - обучающий датафрэйм с необходимыми для фильтрации признаками\n",
    "            y_train - соответствующий начальные df, со значением таргета(необходим для расчёта значений)\n",
    "            filters_list - список используемых фильтров\n",
    "            trsh_hld - минимально допустимый процент понижения BR на отфильтрованной выборке\n",
    "                    (если необходимо понизить BR на 30 процентов, то выставлять trsh_hld=30)\n",
    "                \n",
    "            Данная функция для каждого фильтра, несколько раз добавляет рандомную последовательность фильтров.\n",
    "        На каждом шаге добавления нового фильтра из рандомной последовательности, проводится проверка по trsh_hld,\n",
    "        если результат удовлетворяет требованиям, то текущая комбинация добавляется в итоговый датарэйм,\n",
    "        а фильтр добавляется в результирующий и процесс подбора продолжается.\n",
    "        \n",
    "            Таким образом, получается, что для каждого фильтра в итоговом датафрэйме, будет присутствовать\n",
    "        несколько комбинаций с другими фильтрами, различной длины\"\"\"\n",
    "\n",
    "    from sklearn.utils import shuffle\n",
    "\n",
    "    X_train['target'] = y_train.target\n",
    "\n",
    "    filter_ind = list(range(len(filters_list)))\n",
    "\n",
    "    combinations = pd.DataFrame(columns=['filt_ind', 'BR_dwn_train', 'prt_train', 'BR_curr_train'])\n",
    "\n",
    "    p = 1\n",
    "    i = 0\n",
    "    for ind in range(len(filters_list)):\n",
    "\n",
    "        for _ in range(len(filters_list)):\n",
    "            res = list()\n",
    "            res.append(ind)\n",
    "\n",
    "            train_filt = filter_df([ind], filters_list)\n",
    "\n",
    "            BR_dwn_train, prt_train, BR_curr_train = calculate_values(X_train, train_filt)\n",
    "            curr_max_prt = prt_train\n",
    "\n",
    "            filter_ind = shuffle(filter_ind, random_state=p)\n",
    "            p += 1\n",
    "            for j in filter_ind:\n",
    "                if j in res:\n",
    "                    continue\n",
    "                else:\n",
    "\n",
    "                    check = res + [j]\n",
    "                    train_filt = filter_df(check, filters_list)\n",
    "\n",
    "                    BR_dwn_train, prt_train, BR_curr_train = calculate_values(X_train, train_filt)\n",
    "\n",
    "                    if BR_dwn_train > trsh_hld and prt_train >= 1.02 * curr_max_prt:\n",
    "                        res.append(j)\n",
    "                        curr_max_prt = prt_train\n",
    "                        combinations.loc[i, 'filt_ind'] = res.copy()\n",
    "                        combinations.loc[i, 'BR_dwn_train'] = BR_dwn_train\n",
    "                        combinations.loc[i, 'prt_train'] = prt_train\n",
    "                        combinations.loc[i, 'BR_curr_train'] = BR_curr_train\n",
    "                        i += 1\n",
    "\n",
    "    combinations['filt_ind'] = combinations['filt_ind'].apply(sorted).apply(str)\n",
    "    X_train.drop(columns=['target'], axis=1, inplace=True)\n",
    "    #Возвращает датафрэйм со столбцом, с номерами используемых фильтров, \n",
    "    # и значениями показателей на всех выборках\n",
    "    return combinations.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Greed_search_learn(X_train, y_train, filters_list, trsh_hld=30, max_res_cnt_filters=5):\n",
    "\n",
    "    \"\"\"Функция принимает:\n",
    "            X_train - обучающий датафрэйм с необходимыми для фильтрации признаками\n",
    "            y_train - соответствующий начальные df, со значением таргета(необходим для расчёта значений)\n",
    "            filters_list - список используемых фильтров\n",
    "            trsh_hld - минимально допустимый процент понижения BR на отфильтрованной выборке\n",
    "                    (если необходимо понизить BR на 30 процентов, то выставлять trsh_hld=30)\n",
    "            max_res_cnt_filters - максимальное количество фильтров, которое можно добавить в процессе жадного алгоритма\n",
    "                \n",
    "            Данная функция для каждого фильтра, проходится по всему списку фильтров жадным поиском, и добавляет тот фильтр,\n",
    "        с которым текущая комбинация фильтров даёт наилучший результат, при чём, каждый фильтр проверяется по требованиям trsh_hld,\n",
    "        и специальному условию, что на каждом шаге, объём результирующей выборки должен расти. Если условия не выполняются,\n",
    "        то для текущего фильтра поиск прекращается, результаты заносятся в итоговую таблицу, и начинается поиск для следующего фильтра.\n",
    "        \n",
    "        В результате, получается несколько (не больше количества фильтров) комбинаций, представленных в датафрэйме\"\"\"\n",
    "\n",
    "    def rnd(x):\n",
    "        return round(x)\n",
    "\n",
    "    X_train['target'] = y_train.target\n",
    "\n",
    "    filter_ind = list(range(len(filters_list)))\n",
    "\n",
    "    combinations = pd.DataFrame(columns=['filt_ind', 'BR_dwn_train', 'prt_train', 'BR_curr_train'])\n",
    "\n",
    "    i = 0\n",
    "    for ind in filter_ind:\n",
    "        res = list()\n",
    "        res.append(ind)\n",
    "\n",
    "        train_filt = filter_df(res, filters_list)\n",
    "\n",
    "        BR_dwn_train, prt_train, _ = calculate_values(X_train, train_filt)\n",
    "\n",
    "        curr_prt_max = round(prt_train)\n",
    "\n",
    "        if BR_dwn_train >= trsh_hld:\n",
    "\n",
    "            cnt = max_res_cnt_filters - 1\n",
    "            while cnt != 0:\n",
    "                curr = pd.DataFrame(columns=['filt_ind', 'BR_dwn_train', 'prt_train'])\n",
    "\n",
    "                j = 0\n",
    "                for filt in filter_ind:\n",
    "\n",
    "                    if filt not in res:\n",
    "                        check = res + [filt]\n",
    "                        train_filt = filter_df(check, filters_list)\n",
    "\n",
    "                        BR_dwn_train, prt_train, _ = calculate_values(X_train, train_filt)\n",
    "                        \n",
    "                        if BR_dwn_train > trsh_hld:\n",
    "                            curr.loc[j, 'filt_ind'] = [filt]\n",
    "                            curr.loc[j, 'BR_dwn_train'] = BR_dwn_train\n",
    "                            curr.loc[j, 'prt_train'] = prt_train\n",
    "                            j += 1\n",
    "\n",
    "                if j != 0:\n",
    "\n",
    "                    curr['BR_dwn_train'] = curr['BR_dwn_train'].apply(rnd)\n",
    "                    curr['prt_train'] = curr['prt_train'].apply(rnd)\n",
    "\n",
    "                    curr = curr.sort_values(['prt_train', 'BR_dwn_train'], ascending=[False, False])\n",
    "                    \n",
    "                    if curr['BR_dwn_train'].values[0] >= trsh_hld and curr['prt_train'].values[0] >= curr_prt_max:\n",
    "                        res.append(curr['filt_ind'].values[0][0])\n",
    "                        curr_prt_max = curr['prt_train'].values[0]\n",
    "                    else:\n",
    "                        break\n",
    "\n",
    "                cnt -= 1\n",
    "            \n",
    "            train_filt = filter_df(res, filters_list)\n",
    "\n",
    "            BR_dwn_train, prt_train, BR_curr_train = calculate_values(X_train, train_filt)\n",
    "                        \n",
    "            combinations.loc[i, 'filt_ind'] = res.copy()\n",
    "            combinations.loc[i, 'BR_dwn_train'] = BR_dwn_train\n",
    "            combinations.loc[i, 'prt_train'] = prt_train\n",
    "            combinations.loc[i, 'BR_curr_train'] = BR_curr_train\n",
    "            i += 1\n",
    "    combinations['filt_ind'] = combinations['filt_ind'].apply(sorted).apply(str)\n",
    "\n",
    "    X_train.drop(columns=['target'], axis=1, inplace=True)   \n",
    "    #Возвращает датафрэйм со столбцом, с номерами используемых фильтров, \n",
    "    # и значениями показателей на всех выборках\n",
    "    return combinations.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_sample_data(X_train, X_test, X_out, \n",
    "                    y_train, y_test, y_out, \n",
    "                    filters_list, combinations):\n",
    "\n",
    "    \"\"\"Функция принимает:\n",
    "            X_train, X_test, X_out - датафрэймы с необходимыми для фильтрации признаками\n",
    "            y_train, y_test, y_out - соответствующий df, со значением таргета(необходим для расчёта значений)\n",
    "            filters_list - список используемых фильтров\n",
    "            combinations - датафрэйм, являющийся результатом работы функций \"Greed_search_learn\" или \"Random_step_by_step_learn\"\n",
    "\n",
    "                \n",
    "            Данная функция по значениям комбинация в колонке 'filt_ind' датафрэйма combinations,\n",
    "        рассчитывает значения 'BR_dwn', 'prt', 'BR_curr', для train, test и out выборок.\n",
    "            \n",
    "            В результате получается датафрэйм, с результатами для всех выборок по фильтрам,\n",
    "        которые были получены, в процессе 'обучения' на train\"\"\"\n",
    "\n",
    "    #В filtr_ind - хранятся строки со списками, поэтому перевожуперевожу их обратно в списки\n",
    "    to_check = list(combinations['filt_ind'].values)\n",
    "    to_check = list(map(lambda x: x[1:-1].split(', '), to_check))\n",
    "\n",
    "    #Для получения индексов, перевожу строковые числа в int\n",
    "\n",
    "    \n",
    "    result =  pd.DataFrame(columns=['filters', 'filt_cnt', 'BR_dwn_train', 'prt_train', 'BR_curr_train',\n",
    "                                        'BR_dwn_test', 'prt_test', 'BR_curr_test', \n",
    "                                        'BR_dwn_out', 'prt_out', 'BR_curr_out'])\n",
    "\n",
    "    \n",
    "    X_train['target'] = y_train.target\n",
    "    X_test['target'] = y_test.target\n",
    "    X_out['target'] = y_out.target\n",
    "    \n",
    "    i = 0\n",
    "    for val in to_check:\n",
    "        inxs = list(map(lambda x: int(x), val))\n",
    "\n",
    "        filt = filter_df(inxs, filters_list)\n",
    "\n",
    "        BR_dwn_train, prt_train, BR_curr_train = calculate_values(X_train, filt)\n",
    "        BR_dwn_test, prt_test, BR_curr_test = calculate_values(X_test, filt)\n",
    "        BR_dwn_out, prt_out, BR_curr_out = calculate_values(X_out, filt)\n",
    "                    \n",
    "        result.loc[i, 'filters'] = filt\n",
    "        result.loc[i, 'filt_cnt'] = len(inxs)\n",
    "        result.loc[i, 'BR_dwn_train'] = BR_dwn_train\n",
    "        result.loc[i, 'prt_train'] = prt_train\n",
    "        result.loc[i, 'BR_curr_train'] = BR_curr_train\n",
    "        result.loc[i, 'BR_dwn_test'] = BR_dwn_test\n",
    "        result.loc[i, 'prt_test'] = prt_test\n",
    "        result.loc[i, 'BR_curr_test'] = BR_curr_test\n",
    "        result.loc[i, 'BR_dwn_out'] = BR_dwn_out\n",
    "        result.loc[i, 'prt_out'] = prt_out\n",
    "        result.loc[i, 'BR_curr_out'] = BR_curr_out\n",
    "        i += 1\n",
    "\n",
    "    X_train.drop(columns=['target'], axis=1, inplace=True)\n",
    "    X_test.drop(columns=['target'], axis=1, inplace=True)\n",
    "    X_out.drop(columns=['target'], axis=1, inplace=True)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_sample_data_with_learning(X_train, X_test, X_out, \n",
    "                                  y_train, y_test, y_out, \n",
    "                                  filters_list, trsh_hld=30, \n",
    "                                  type_search='greed', max_res_cnt_filters=None):\n",
    "\n",
    "    \"\"\"Функция принимает:\n",
    "            X_train, X_test, X_out - датафрэймы с необходимыми для фильтрации признаками\n",
    "            y_train, y_test, y_out - соответствующий df, со значением таргета(необходим для расчёта значений)\n",
    "            filtr_cnt - датафрэйм, являющийся результатом работы функций \"Greed_search_learn\" или \"Random_step_by_step_learn\"\n",
    "            trsh_hld - минимально допустимый процент понижения BR на отфильтрованной выборке\n",
    "\n",
    "            type - тип поиска комбинаций ('random' - random_step_by_step_learn\n",
    "                                          'greed' - Greed_search_learn, или different_cnt_greed_learn)\n",
    "\n",
    "            max_res_cnt_filters - (указывать в слуае type='greed')\n",
    "                                    - Если передать число - type == int, то функция рассчитает по Greed_search_learn, \n",
    "                                то есть для определённого максимального значения фильтров\n",
    "                                    - Если передать список - type == list, то функция рассчитает по different_cnt_greed_learn,\n",
    "                                то есть для различных значений макс. кол-ва фильтров.\n",
    "\n",
    "            Данная функция сначала 'обучается' на указанной X_train, y_train - выборках, а потом,\n",
    "        рассчитывает значения 'BR_dwn', 'prt', 'BR_curr', для train, test и out выборок.\n",
    "            \n",
    "            В результате получается датафрэйм, с результатами для всех выборок по фильтрам,\n",
    "        которые были получены, в процессе 'обучения' на train\"\"\"\n",
    "\n",
    "    if type_search == 'greed':\n",
    "        combinations = Greed_search_learn(X_train, y_train, filters_list, trsh_hld=trsh_hld, max_res_cnt_filters=max_res_cnt_filters)\n",
    "\n",
    "    elif type_search == 'random':\n",
    "        combinations = random_step_by_step_learn(X_train, y_train, filters_list, trsh_hld=trsh_hld)\n",
    "        \n",
    "    else:\n",
    "        combinations = Greed_search_learn(X_train, y_train, filters_list, trsh_hld=trsh_hld, max_res_cnt_filters=max_res_cnt_filters)\n",
    "\n",
    "    #В filtr_num - хранятся строки со списками, поэтому перевожуперевожу их обратно в списки\n",
    "    to_check = list(combinations['filtr_num'].values)\n",
    "    to_check = list(map(lambda x: x[1:-1].split(', '), to_check))\n",
    "\n",
    "    #Для получения индексов, перевожу строковые числа в int\n",
    "\n",
    "    \n",
    "    result =  pd.DataFrame(columns=['filt_num', 'BR_dwn_train', 'prt_train', 'BR_curr_train',\n",
    "                                        'BR_dwn_test', 'prt_test', 'BR_curr_test', \n",
    "                                        'BR_dwn_out', 'prt_out', 'BR_curr_out'])\n",
    "\n",
    "    \n",
    "    X_train['target'] = y_train\n",
    "    X_test['target'] = y_test\n",
    "    X_out['target'] = y_out\n",
    "    \n",
    "    i = 0\n",
    "    for val in to_check:\n",
    "        inxs = list(map(lambda x: int(x), val))\n",
    "\n",
    "        filt = filter_df(inxs, filters_list)\n",
    "\n",
    "        BR_dwn_train, prt_train, BR_curr_train = calculate_values(X_train, filt)\n",
    "        BR_dwn_test, prt_test, BR_curr_test = calculate_values(X_test, filt)\n",
    "        BR_dwn_out, prt_out, BR_curr_out = calculate_values(X_out, filt)\n",
    "                    \n",
    "        result.loc[i, 'filt_num'] = inxs.copy()\n",
    "        result.loc[i, 'BR_dwn_train'] = BR_dwn_train\n",
    "        result.loc[i, 'prt_train'] = prt_train\n",
    "        result.loc[i, 'BR_curr_train'] = BR_curr_train\n",
    "        result.loc[i, 'BR_dwn_test'] = BR_dwn_test\n",
    "        result.loc[i, 'prt_test'] = prt_test\n",
    "        result.loc[i, 'BR_curr_test'] = BR_curr_test\n",
    "        result.loc[i, 'BR_dwn_out'] = BR_dwn_out\n",
    "        result.loc[i, 'prt_out'] = prt_out\n",
    "        result.loc[i, 'BR_curr_out'] = BR_curr_out\n",
    "        i += 1\n",
    "\n",
    "    X_train.drop(columns=['target'], axis=1, inplace=True)\n",
    "    X_test.drop(columns=['target'], axis=1, inplace=True)\n",
    "    X_out.drop(columns=['target'], axis=1, inplace=True)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Применение "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars = list(X_train.columns) #задаю список переменных, в данном случае, беру все столбцы датафрэйма, в реальной работе, лучше передавать \n",
    "                             #отобранные признаки\n",
    "rules_branch = rules_search(X_train, y_train, vars, BR_dwn=30) #получившиеся рулы при отборе каждой ветки по отдельности"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars = list(X_train.columns) #задаю список переменных, в данном случае, беру все столбцы датафрэйма, в реальной работе, лучше передавать \n",
    "                             #отобранные признаки\n",
    "rules_trees = rules_search_up_down(X_train, y_train, vars, BR_dwn=30) #получившиеся рулы при отборе веток и дальнейшем их объединениии"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "rules_trees = rules_trees[rules_trees['BR'].isna()==False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rule</th>\n",
       "      <th>BR</th>\n",
       "      <th>Segm_share</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>((a6m_overdue2total_cnt_pdl &lt;= -0.197)&amp;(capsTo...</td>\n",
       "      <td>0.055</td>\n",
       "      <td>0.772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>((sent2avg_PDL_am &lt;= -0.157)&amp;(days_since_last_...</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>((sent2avg_PDL_am &lt;= -0.157)&amp;(capsTotalAmountL...</td>\n",
       "      <td>0.052</td>\n",
       "      <td>0.748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>((charge_k3 &lt;= -0.387)&amp;(capsTotalAmountL6m &gt; -...</td>\n",
       "      <td>0.055</td>\n",
       "      <td>0.745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>((crd_sum_IL2total &lt;= -0.251)&amp;(fcb_last_open_d...</td>\n",
       "      <td>0.054</td>\n",
       "      <td>0.745</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  rule     BR  Segm_share\n",
       "403  ((a6m_overdue2total_cnt_pdl <= -0.197)&(capsTo...  0.055       0.772\n",
       "265  ((sent2avg_PDL_am <= -0.157)&(days_since_last_...  0.053       0.750\n",
       "477  ((sent2avg_PDL_am <= -0.157)&(capsTotalAmountL...  0.052       0.748\n",
       "121  ((charge_k3 <= -0.387)&(capsTotalAmountL6m > -...  0.055       0.745\n",
       "262  ((crd_sum_IL2total <= -0.251)&(fcb_last_open_d...  0.054       0.745"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rules_trees.head() #получившиеся рулы на объединённых ветках"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rules_branch.head() #получившиеся рулы на отдельных объединённых ветках"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Проверка рандомного поиска"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ветки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = list(rules_branch.head(20).rule.values) + list(rules_branch.head(200).tail(20).rule.values) + list(rules_branch.tail(40).rule.values) #беру несколько рулов для проверки\n",
    "k = 1\n",
    "filters_list = shuffle(r, random_state=k)[:20] #из перемешанного списка рулов беру 20 рандомных\n",
    "educ = random_step_by_step_learn(X_train, y_train, filters_list, trsh_hld=30) #Обучаюсь на трэйн выборке по этим 20 веткам\n",
    "res_br_rnd = all_sample_data(X_train, X_test, X_out, \n",
    "                y_train, y_test, y_out, \n",
    "                filters_list, educ) # вывожу результаты данных веток на все выборки\n",
    "for q in range(5): #повторяю несколько раз дл увеличения объёма результата\n",
    "    if q == 4:\n",
    "        break\n",
    "    k += 1\n",
    "    filters_list = shuffle(r, random_state=k)[:20]\n",
    "    educ = random_step_by_step_learn(X_train, y_train, filters_list, trsh_hld=30)\n",
    "    curr_res = all_sample_data(X_train, X_test, X_out, \n",
    "                    y_train, y_test, y_out, \n",
    "                    filters_list, educ)\n",
    "    res_br_rnd = pd.concat([res_br_rnd, curr_res.copy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filters</th>\n",
       "      <th>filt_cnt</th>\n",
       "      <th>BR_dwn_train</th>\n",
       "      <th>prt_train</th>\n",
       "      <th>BR_curr_train</th>\n",
       "      <th>BR_dwn_test</th>\n",
       "      <th>prt_test</th>\n",
       "      <th>BR_curr_test</th>\n",
       "      <th>BR_dwn_out</th>\n",
       "      <th>prt_out</th>\n",
       "      <th>BR_curr_out</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>((cnt_pdl_comp_div_all &lt;= 0.053)&amp;(fcb_last_ope...</td>\n",
       "      <td>4</td>\n",
       "      <td>32.894</td>\n",
       "      <td>74.937</td>\n",
       "      <td>5.38</td>\n",
       "      <td>28.208</td>\n",
       "      <td>72.918</td>\n",
       "      <td>5.748</td>\n",
       "      <td>27.07</td>\n",
       "      <td>80.722</td>\n",
       "      <td>5.831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>((a1y_overdue2total_cnt_pdl &gt; -0.16)&amp;(fcb_firs...</td>\n",
       "      <td>3</td>\n",
       "      <td>32.139</td>\n",
       "      <td>75.374</td>\n",
       "      <td>5.44</td>\n",
       "      <td>27.395</td>\n",
       "      <td>73.025</td>\n",
       "      <td>5.813</td>\n",
       "      <td>27.07</td>\n",
       "      <td>80.722</td>\n",
       "      <td>5.831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>((cnt_pdl_comp_div_all &lt;= 0.053)&amp;(fcb_last_ope...</td>\n",
       "      <td>3</td>\n",
       "      <td>33.092</td>\n",
       "      <td>74.729</td>\n",
       "      <td>5.364</td>\n",
       "      <td>26.476</td>\n",
       "      <td>73.025</td>\n",
       "      <td>5.887</td>\n",
       "      <td>27.128</td>\n",
       "      <td>80.787</td>\n",
       "      <td>5.826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>((sent2last_cred &gt; -0.437)&amp;(days_from_last_c_d...</td>\n",
       "      <td>3</td>\n",
       "      <td>32.417</td>\n",
       "      <td>75.259</td>\n",
       "      <td>5.418</td>\n",
       "      <td>25.884</td>\n",
       "      <td>73.348</td>\n",
       "      <td>5.934</td>\n",
       "      <td>27.128</td>\n",
       "      <td>80.787</td>\n",
       "      <td>5.826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>((sent2last_cred &gt; -0.437)&amp;(days_from_last_c_d...</td>\n",
       "      <td>4</td>\n",
       "      <td>31.352</td>\n",
       "      <td>75.766</td>\n",
       "      <td>5.503</td>\n",
       "      <td>22.846</td>\n",
       "      <td>73.939</td>\n",
       "      <td>6.177</td>\n",
       "      <td>27.302</td>\n",
       "      <td>80.98</td>\n",
       "      <td>5.812</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               filters filt_cnt BR_dwn_train  \\\n",
       "112  ((cnt_pdl_comp_div_all <= 0.053)&(fcb_last_ope...        4       32.894   \n",
       "170  ((a1y_overdue2total_cnt_pdl > -0.16)&(fcb_firs...        3       32.139   \n",
       "430  ((cnt_pdl_comp_div_all <= 0.053)&(fcb_last_ope...        3       33.092   \n",
       "87   ((sent2last_cred > -0.437)&(days_from_last_c_d...        3       32.417   \n",
       "91   ((sent2last_cred > -0.437)&(days_from_last_c_d...        4       31.352   \n",
       "\n",
       "    prt_train BR_curr_train BR_dwn_test prt_test BR_curr_test BR_dwn_out  \\\n",
       "112    74.937          5.38      28.208   72.918        5.748      27.07   \n",
       "170    75.374          5.44      27.395   73.025        5.813      27.07   \n",
       "430    74.729         5.364      26.476   73.025        5.887     27.128   \n",
       "87     75.259         5.418      25.884   73.348        5.934     27.128   \n",
       "91     75.766         5.503      22.846   73.939        6.177     27.302   \n",
       "\n",
       "    prt_out BR_curr_out  \n",
       "112  80.722       5.831  \n",
       "170  80.722       5.831  \n",
       "430  80.787       5.826  \n",
       "87   80.787       5.826  \n",
       "91    80.98       5.812  "
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_br_rnd[(res_br_rnd['BR_dwn_out']>27)&(res_br_rnd['prt_out']>80)].head() #выбираю необходимый результат"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Аналогичным образом проверяю работу поиска рулов но веткам \"деревьям\" для жадного и рандомного алгоритмов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Деревья"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = list(rules_branch.rule.values)\n",
    "k = 1\n",
    "filters_list = shuffle(r, random_state=k)[:20]\n",
    "educ = random_step_by_step_learn(X_train, y_train, filters_list, trsh_hld=30)\n",
    "res_tr_rnd = all_sample_data(X_train, X_test, X_out, \n",
    "                y_train, y_test, y_out, \n",
    "                filters_list, educ)\n",
    "for q in range(5):\n",
    "    if q == 4:\n",
    "        break\n",
    "    k += 1\n",
    "    filters_list = shuffle(r, random_state=k)[:20]\n",
    "    educ = random_step_by_step_learn(X_train, y_train, filters_list, trsh_hld=30)\n",
    "    curr_res = all_sample_data(X_train, X_test, X_out, \n",
    "                    y_train, y_test, y_out, \n",
    "                    filters_list, educ)\n",
    "    res_tr_rnd = pd.concat([res_tr_rnd, curr_res.copy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filters</th>\n",
       "      <th>filt_cnt</th>\n",
       "      <th>BR_dwn_train</th>\n",
       "      <th>prt_train</th>\n",
       "      <th>BR_curr_train</th>\n",
       "      <th>BR_dwn_test</th>\n",
       "      <th>prt_test</th>\n",
       "      <th>BR_curr_test</th>\n",
       "      <th>BR_dwn_out</th>\n",
       "      <th>prt_out</th>\n",
       "      <th>BR_curr_out</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1222</th>\n",
       "      <td>((cnt_pdl_act_no_Crd &gt; -0.701)&amp;(capsL1m &gt; 0.12...</td>\n",
       "      <td>2</td>\n",
       "      <td>34.773</td>\n",
       "      <td>70.928</td>\n",
       "      <td>5.229</td>\n",
       "      <td>27.553</td>\n",
       "      <td>69.479</td>\n",
       "      <td>5.8</td>\n",
       "      <td>27.535</td>\n",
       "      <td>76.789</td>\n",
       "      <td>5.793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1015</th>\n",
       "      <td>((avg_credit_term &gt; -0.199)&amp;(avg_credit_term &gt;...</td>\n",
       "      <td>3</td>\n",
       "      <td>33.379</td>\n",
       "      <td>70.306</td>\n",
       "      <td>5.341</td>\n",
       "      <td>34.521</td>\n",
       "      <td>68.673</td>\n",
       "      <td>5.243</td>\n",
       "      <td>27.504</td>\n",
       "      <td>78.981</td>\n",
       "      <td>5.796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>742</th>\n",
       "      <td>((cnt_pdl_act_div_all_no_Crd &gt; 0.049)&amp;(sum_pen...</td>\n",
       "      <td>3</td>\n",
       "      <td>31.6</td>\n",
       "      <td>72.679</td>\n",
       "      <td>5.483</td>\n",
       "      <td>24.985</td>\n",
       "      <td>71.574</td>\n",
       "      <td>6.006</td>\n",
       "      <td>27.117</td>\n",
       "      <td>75.242</td>\n",
       "      <td>5.827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>744</th>\n",
       "      <td>((active_200k &gt; -0.32)&amp;(days_since_last_due &gt; ...</td>\n",
       "      <td>3</td>\n",
       "      <td>38.711</td>\n",
       "      <td>71.735</td>\n",
       "      <td>4.913</td>\n",
       "      <td>32.487</td>\n",
       "      <td>69.586</td>\n",
       "      <td>5.405</td>\n",
       "      <td>27.399</td>\n",
       "      <td>77.756</td>\n",
       "      <td>5.804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>858</th>\n",
       "      <td>((active_200k &gt; -0.32)&amp;(days_since_last_due &gt; ...</td>\n",
       "      <td>4</td>\n",
       "      <td>37.727</td>\n",
       "      <td>73.831</td>\n",
       "      <td>4.992</td>\n",
       "      <td>31.343</td>\n",
       "      <td>71.359</td>\n",
       "      <td>5.497</td>\n",
       "      <td>27.207</td>\n",
       "      <td>78.659</td>\n",
       "      <td>5.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>950</th>\n",
       "      <td>((crd_sum_less5dpd_12m2total &gt; -0.135)&amp;(avg_li...</td>\n",
       "      <td>4</td>\n",
       "      <td>34.367</td>\n",
       "      <td>74.43</td>\n",
       "      <td>5.262</td>\n",
       "      <td>25.721</td>\n",
       "      <td>73.186</td>\n",
       "      <td>5.947</td>\n",
       "      <td>28.525</td>\n",
       "      <td>76.725</td>\n",
       "      <td>5.714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>916</th>\n",
       "      <td>((open_date_cnt_90d &gt; -0.706)&amp;(capsTotalAmount...</td>\n",
       "      <td>4</td>\n",
       "      <td>32.885</td>\n",
       "      <td>74.499</td>\n",
       "      <td>5.38</td>\n",
       "      <td>25.557</td>\n",
       "      <td>73.025</td>\n",
       "      <td>5.96</td>\n",
       "      <td>28.705</td>\n",
       "      <td>76.918</td>\n",
       "      <td>5.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1643</th>\n",
       "      <td>((min_PDL_planned_close_date_no_Crd &gt; -0.166)&amp;...</td>\n",
       "      <td>4</td>\n",
       "      <td>38.305</td>\n",
       "      <td>68.003</td>\n",
       "      <td>4.946</td>\n",
       "      <td>33.468</td>\n",
       "      <td>66.577</td>\n",
       "      <td>5.327</td>\n",
       "      <td>27.117</td>\n",
       "      <td>75.242</td>\n",
       "      <td>5.827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421</th>\n",
       "      <td>((avg_credit_term &gt; -0.199)&amp;(avg_credit_term &gt;...</td>\n",
       "      <td>4</td>\n",
       "      <td>33.412</td>\n",
       "      <td>71.205</td>\n",
       "      <td>5.338</td>\n",
       "      <td>34.466</td>\n",
       "      <td>69.64</td>\n",
       "      <td>5.247</td>\n",
       "      <td>27.74</td>\n",
       "      <td>79.239</td>\n",
       "      <td>5.777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>((a6m_overdue2total_cnt_pdl &gt; -0.197)&amp;(crd_sum...</td>\n",
       "      <td>4</td>\n",
       "      <td>38.155</td>\n",
       "      <td>68.302</td>\n",
       "      <td>4.958</td>\n",
       "      <td>32.055</td>\n",
       "      <td>67.168</td>\n",
       "      <td>5.44</td>\n",
       "      <td>28.556</td>\n",
       "      <td>75.629</td>\n",
       "      <td>5.712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>917</th>\n",
       "      <td>((open_date_cnt_90d &gt; -0.706)&amp;(capsTotalAmount...</td>\n",
       "      <td>5</td>\n",
       "      <td>32.349</td>\n",
       "      <td>76.457</td>\n",
       "      <td>5.423</td>\n",
       "      <td>24.899</td>\n",
       "      <td>75.067</td>\n",
       "      <td>6.013</td>\n",
       "      <td>27.489</td>\n",
       "      <td>80.077</td>\n",
       "      <td>5.797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1332</th>\n",
       "      <td>((active_200k &gt; -0.32)&amp;(days_since_last_due &gt; ...</td>\n",
       "      <td>5</td>\n",
       "      <td>30.853</td>\n",
       "      <td>72.725</td>\n",
       "      <td>5.543</td>\n",
       "      <td>27.189</td>\n",
       "      <td>71.897</td>\n",
       "      <td>5.83</td>\n",
       "      <td>27.699</td>\n",
       "      <td>78.079</td>\n",
       "      <td>5.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444</th>\n",
       "      <td>((avg_credit_term &gt; -0.199)&amp;(avg_credit_term &gt;...</td>\n",
       "      <td>5</td>\n",
       "      <td>33.648</td>\n",
       "      <td>71.458</td>\n",
       "      <td>5.319</td>\n",
       "      <td>34.668</td>\n",
       "      <td>69.855</td>\n",
       "      <td>5.231</td>\n",
       "      <td>27.858</td>\n",
       "      <td>79.368</td>\n",
       "      <td>5.768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1182</th>\n",
       "      <td>((cnt_pdl_act_div_all_no_Crd &gt; 0.049)&amp;(sum_dpd...</td>\n",
       "      <td>5</td>\n",
       "      <td>37.529</td>\n",
       "      <td>71.297</td>\n",
       "      <td>5.008</td>\n",
       "      <td>33.961</td>\n",
       "      <td>70.124</td>\n",
       "      <td>5.287</td>\n",
       "      <td>29.812</td>\n",
       "      <td>76.983</td>\n",
       "      <td>5.611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1333</th>\n",
       "      <td>((active_200k &gt; -0.32)&amp;(days_since_last_due &gt; ...</td>\n",
       "      <td>6</td>\n",
       "      <td>31.3</td>\n",
       "      <td>74.453</td>\n",
       "      <td>5.507</td>\n",
       "      <td>27.82</td>\n",
       "      <td>73.455</td>\n",
       "      <td>5.779</td>\n",
       "      <td>27.267</td>\n",
       "      <td>78.723</td>\n",
       "      <td>5.815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>((open_date_cnt_90d &gt; -0.706)&amp;(capsTotalAmount...</td>\n",
       "      <td>6</td>\n",
       "      <td>33.593</td>\n",
       "      <td>72.264</td>\n",
       "      <td>5.324</td>\n",
       "      <td>24.703</td>\n",
       "      <td>71.306</td>\n",
       "      <td>6.029</td>\n",
       "      <td>27.304</td>\n",
       "      <td>75.435</td>\n",
       "      <td>5.812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>659</th>\n",
       "      <td>((charge_k1 &gt; -0.675)&amp;(bor_age &gt; -0.088)&amp;(max_...</td>\n",
       "      <td>6</td>\n",
       "      <td>36.924</td>\n",
       "      <td>73.347</td>\n",
       "      <td>5.057</td>\n",
       "      <td>27.374</td>\n",
       "      <td>74.852</td>\n",
       "      <td>5.815</td>\n",
       "      <td>27.579</td>\n",
       "      <td>77.95</td>\n",
       "      <td>5.79</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                filters filt_cnt BR_dwn_train  \\\n",
       "1222  ((cnt_pdl_act_no_Crd > -0.701)&(capsL1m > 0.12...        2       34.773   \n",
       "1015  ((avg_credit_term > -0.199)&(avg_credit_term >...        3       33.379   \n",
       "742   ((cnt_pdl_act_div_all_no_Crd > 0.049)&(sum_pen...        3         31.6   \n",
       "744   ((active_200k > -0.32)&(days_since_last_due > ...        3       38.711   \n",
       "858   ((active_200k > -0.32)&(days_since_last_due > ...        4       37.727   \n",
       "950   ((crd_sum_less5dpd_12m2total > -0.135)&(avg_li...        4       34.367   \n",
       "916   ((open_date_cnt_90d > -0.706)&(capsTotalAmount...        4       32.885   \n",
       "1643  ((min_PDL_planned_close_date_no_Crd > -0.166)&...        4       38.305   \n",
       "421   ((avg_credit_term > -0.199)&(avg_credit_term >...        4       33.412   \n",
       "273   ((a6m_overdue2total_cnt_pdl > -0.197)&(crd_sum...        4       38.155   \n",
       "917   ((open_date_cnt_90d > -0.706)&(capsTotalAmount...        5       32.349   \n",
       "1332  ((active_200k > -0.32)&(days_since_last_due > ...        5       30.853   \n",
       "444   ((avg_credit_term > -0.199)&(avg_credit_term >...        5       33.648   \n",
       "1182  ((cnt_pdl_act_div_all_no_Crd > 0.049)&(sum_dpd...        5       37.529   \n",
       "1333  ((active_200k > -0.32)&(days_since_last_due > ...        6         31.3   \n",
       "886   ((open_date_cnt_90d > -0.706)&(capsTotalAmount...        6       33.593   \n",
       "659   ((charge_k1 > -0.675)&(bor_age > -0.088)&(max_...        6       36.924   \n",
       "\n",
       "     prt_train BR_curr_train BR_dwn_test prt_test BR_curr_test BR_dwn_out  \\\n",
       "1222    70.928         5.229      27.553   69.479          5.8     27.535   \n",
       "1015    70.306         5.341      34.521   68.673        5.243     27.504   \n",
       "742     72.679         5.483      24.985   71.574        6.006     27.117   \n",
       "744     71.735         4.913      32.487   69.586        5.405     27.399   \n",
       "858     73.831         4.992      31.343   71.359        5.497     27.207   \n",
       "950      74.43         5.262      25.721   73.186        5.947     28.525   \n",
       "916     74.499          5.38      25.557   73.025         5.96     28.705   \n",
       "1643    68.003         4.946      33.468   66.577        5.327     27.117   \n",
       "421     71.205         5.338      34.466    69.64        5.247      27.74   \n",
       "273     68.302         4.958      32.055   67.168         5.44     28.556   \n",
       "917     76.457         5.423      24.899   75.067        6.013     27.489   \n",
       "1332    72.725         5.543      27.189   71.897         5.83     27.699   \n",
       "444     71.458         5.319      34.668   69.855        5.231     27.858   \n",
       "1182    71.297         5.008      33.961   70.124        5.287     29.812   \n",
       "1333    74.453         5.507       27.82   73.455        5.779     27.267   \n",
       "886     72.264         5.324      24.703   71.306        6.029     27.304   \n",
       "659     73.347         5.057      27.374   74.852        5.815     27.579   \n",
       "\n",
       "     prt_out BR_curr_out  \n",
       "1222  76.789       5.793  \n",
       "1015  78.981       5.796  \n",
       "742   75.242       5.827  \n",
       "744   77.756       5.804  \n",
       "858   78.659        5.82  \n",
       "950   76.725       5.714  \n",
       "916   76.918         5.7  \n",
       "1643  75.242       5.827  \n",
       "421   79.239       5.777  \n",
       "273   75.629       5.712  \n",
       "917   80.077       5.797  \n",
       "1332  78.079        5.78  \n",
       "444   79.368       5.768  \n",
       "1182  76.983       5.611  \n",
       "1333  78.723       5.815  \n",
       "886   75.435       5.812  \n",
       "659    77.95        5.79  "
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_tr_rnd[(res_tr_rnd['BR_dwn_out']>27)&(res_tr_rnd['prt_out']>75)].sort_values('filt_cnt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Проверка жадного поиска"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ветки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [04:44<00:00, 40.59s/it]\n"
     ]
    }
   ],
   "source": [
    "r = list(rules_branch.head(20).rule.values) + list(rules_branch.head(200).tail(20).rule.values) + list(rules_branch.tail(40).rule.values)\n",
    "k = 1\n",
    "filters_list = shuffle(r, random_state=k)[:20]\n",
    "educ_gr = Greed_search_learn(X_train, y_train, filters_list, trsh_hld=30, max_res_cnt_filters=4)\n",
    "res_br_gr = all_sample_data(X_train, X_test, X_out, \n",
    "                y_train, y_test, y_out, \n",
    "                filters_list, educ_gr)\n",
    "m = 2\n",
    "for i in tqdm(range(7)):\n",
    "    k += 1\n",
    "    filters_list = shuffle(r, random_state=k)[:20]\n",
    "    educ_gr = Greed_search_learn(X_train, y_train, filters_list, trsh_hld=30, max_res_cnt_filters=m//1)\n",
    "    curr_res_gr = all_sample_data(X_train, X_test, X_out, \n",
    "                    y_train, y_test, y_out, \n",
    "                    filters_list, educ_gr)\n",
    "    res_br_gr = pd.concat([res_br_gr, curr_res_gr.copy()])\n",
    "    m += 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filt_ind</th>\n",
       "      <th>BR_dwn_train</th>\n",
       "      <th>prt_train</th>\n",
       "      <th>BR_curr_train</th>\n",
       "      <th>BR_dwn_test</th>\n",
       "      <th>prt_test</th>\n",
       "      <th>BR_curr_test</th>\n",
       "      <th>BR_dwn_out</th>\n",
       "      <th>prt_out</th>\n",
       "      <th>BR_curr_out</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[4, 5]</td>\n",
       "      <td>30.172</td>\n",
       "      <td>75.72</td>\n",
       "      <td>5.598</td>\n",
       "      <td>19.156</td>\n",
       "      <td>73.885</td>\n",
       "      <td>6.473</td>\n",
       "      <td>26.0</td>\n",
       "      <td>78.466</td>\n",
       "      <td>5.916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[4, 5, 8]</td>\n",
       "      <td>32.521</td>\n",
       "      <td>75.374</td>\n",
       "      <td>5.41</td>\n",
       "      <td>26.799</td>\n",
       "      <td>73.348</td>\n",
       "      <td>5.861</td>\n",
       "      <td>26.247</td>\n",
       "      <td>80.916</td>\n",
       "      <td>5.896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[5, 8, 16]</td>\n",
       "      <td>31.164</td>\n",
       "      <td>75.559</td>\n",
       "      <td>5.518</td>\n",
       "      <td>24.441</td>\n",
       "      <td>73.724</td>\n",
       "      <td>6.05</td>\n",
       "      <td>27.128</td>\n",
       "      <td>80.787</td>\n",
       "      <td>5.826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[5, 8, 18]</td>\n",
       "      <td>31.576</td>\n",
       "      <td>76.434</td>\n",
       "      <td>5.485</td>\n",
       "      <td>25.259</td>\n",
       "      <td>74.53</td>\n",
       "      <td>5.984</td>\n",
       "      <td>27.417</td>\n",
       "      <td>81.109</td>\n",
       "      <td>5.803</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      filt_ind BR_dwn_train prt_train BR_curr_train BR_dwn_test prt_test  \\\n",
       "3       [4, 5]       30.172     75.72         5.598      19.156   73.885   \n",
       "4    [4, 5, 8]       32.521    75.374          5.41      26.799   73.348   \n",
       "13  [5, 8, 16]       31.164    75.559         5.518      24.441   73.724   \n",
       "15  [5, 8, 18]       31.576    76.434         5.485      25.259    74.53   \n",
       "\n",
       "   BR_curr_test BR_dwn_out prt_out BR_curr_out  \n",
       "3         6.473       26.0  78.466       5.916  \n",
       "4         5.861     26.247  80.916       5.896  \n",
       "13         6.05     27.128  80.787       5.826  \n",
       "15        5.984     27.417  81.109       5.803  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_br_gr[(res_br_gr['BR_dwn_out']>25)&(res_br_gr['prt_out']>70)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Деревья"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [04:46<00:00, 40.98s/it]\n"
     ]
    }
   ],
   "source": [
    "r = list(rules_branch.rule.values)\n",
    "k = 1\n",
    "filters_list = shuffle(r, random_state=k)[:20]\n",
    "educ_gr = Greed_search_learn(X_train, y_train, filters_list, trsh_hld=30, max_res_cnt_filters=4)\n",
    "res_tr_gr = all_sample_data(X_train, X_test, X_out, \n",
    "                y_train, y_test, y_out, \n",
    "                filters_list, educ_gr)\n",
    "m = 2\n",
    "for i in tqdm(range(7)):\n",
    "    k += 1\n",
    "    filters_list = shuffle(r, random_state=k)[:20]\n",
    "    educ_gr = Greed_search_learn(X_train, y_train, filters_list, trsh_hld=30, max_res_cnt_filters=m//1)\n",
    "    curr_res_gr = all_sample_data(X_train, X_test, X_out, \n",
    "                    y_train, y_test, y_out, \n",
    "                    filters_list, educ_gr)\n",
    "    res_tr_gr = pd.concat([res_tr_gr, curr_res_gr.copy()])\n",
    "    m += 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filt_ind</th>\n",
       "      <th>BR_dwn_train</th>\n",
       "      <th>prt_train</th>\n",
       "      <th>BR_curr_train</th>\n",
       "      <th>BR_dwn_test</th>\n",
       "      <th>prt_test</th>\n",
       "      <th>BR_curr_test</th>\n",
       "      <th>BR_dwn_out</th>\n",
       "      <th>prt_out</th>\n",
       "      <th>BR_curr_out</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[4, 6, 19]</td>\n",
       "      <td>33.512</td>\n",
       "      <td>76.065</td>\n",
       "      <td>5.33</td>\n",
       "      <td>28.373</td>\n",
       "      <td>74.96</td>\n",
       "      <td>5.735</td>\n",
       "      <td>25.952</td>\n",
       "      <td>80.593</td>\n",
       "      <td>5.92</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     filt_ind BR_dwn_train prt_train BR_curr_train BR_dwn_test prt_test  \\\n",
       "4  [4, 6, 19]       33.512    76.065          5.33      28.373    74.96   \n",
       "\n",
       "  BR_curr_test BR_dwn_out prt_out BR_curr_out  \n",
       "4        5.735     25.952  80.593        5.92  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_tr_gr[(res_tr_gr['BR_dwn_out']>25)&(res_tr_gr['prt_out']>70)] #Результат по объединённым веткам одного дерева"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
